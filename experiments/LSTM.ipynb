{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Moderation Classifier\n",
        "\n",
        "This script trains a binary classifier using a LSTM neural network with embeddings, validation split, and early stopping.\n",
        "\n"
      ],
      "metadata": {
        "id": "iEn9m0xnVcm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import re\n",
        "from collections import Counter\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "wLjogV0-W-SI"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "W9gMHH7lab3B"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and *preprocess\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "# Preprocess data\n",
        "def clean_text(text):\n",
        "    # Basic cleaning\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text\n",
        "\n",
        "df['cleaned_prompt'] = df['Goal'].apply(clean_text)"
      ],
      "metadata": {
        "id": "Y6ngAJxxav9Y"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create vocabulary\n",
        "\n",
        "def build_vocab(texts, max_size=5000):\n",
        "    counter = Counter()\n",
        "    for text in texts:\n",
        "        counter.update(text.split())\n",
        "\n",
        "    # Keep most common words\n",
        "    common_words = [word for word, _ in counter.most_common(max_size)]\n",
        "\n",
        "    # Create word to index mapping\n",
        "    word_to_idx = {word: idx+2 for idx, word in enumerate(common_words)}\n",
        "    word_to_idx['<pad>'] = 0\n",
        "    word_to_idx['<unk>'] = 1\n",
        "\n",
        "    return word_to_idx\n",
        "\n",
        "word_to_idx = build_vocab(df['cleaned_prompt'])\n",
        "vocab_size = len(word_to_idx)\n",
        "print(f\"Vocabulary size: {vocab_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zssdGmNcSwE",
        "outputId": "2a9e27e2-c8fb-4aa7-8438-ddf7a27216bd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to indices\n",
        "label_to_idx = {'Safe': 0, 'Harmful': 1}\n",
        "df['label_idx'] = df['Label'].map(label_to_idx)\n",
        "\n",
        "# Convert text to sequences of indices\n",
        "def text_to_sequence(text, word_to_idx, max_len=100):\n",
        "    words = text.split()[:max_len]  # Truncate to max_len\n",
        "    sequence = [word_to_idx.get(word, word_to_idx['<unk>']) for word in words]\n",
        "\n",
        "    # Pad sequence\n",
        "    if len(sequence) < max_len:\n",
        "        sequence = sequence + [word_to_idx['<pad>']] * (max_len - len(sequence))\n",
        "\n",
        "    return sequence\n",
        "\n",
        "df['sequence'] = df['cleaned_prompt'].apply(lambda x: text_to_sequence(x, word_to_idx))"
      ],
      "metadata": {
        "id": "YdZfGyVCcerq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['sequence'].values,\n",
        "    df['label_idx'].values,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['label_idx']\n",
        ")"
      ],
      "metadata": {
        "id": "HJS7ZxyrcteZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create PyTorch dataset\n",
        "class PromptDataset(Dataset):\n",
        "    def __init__(self, sequences, labels):\n",
        "        self.sequences = sequences\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sequence = torch.tensor(self.sequences[idx], dtype=torch.long)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return sequence, label\n",
        "\n",
        "# Create dataloaders\n",
        "train_dataset = PromptDataset(X_train, y_train)\n",
        "test_dataset = PromptDataset(X_test, y_test)\n",
        "\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "ejWZLlh9dAEz"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LSTM model\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=True,\n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        # text shape: [batch size, seq length]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded shape: [batch size, seq length, embedding dim]\n",
        "\n",
        "        lstm_output, (hidden, cell) = self.lstm(embedded)\n",
        "        # lstm_output shape: [batch size, seq length, hidden dim * 2]\n",
        "        # hidden shape: [n layers * 2, batch size, hidden dim]\n",
        "\n",
        "        # Concatenate the final forward and backward hidden states\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
        "        # hidden shape: [batch size, hidden dim * 2]\n",
        "\n",
        "        output = self.fc(hidden)\n",
        "        # output shape: [batch size, output dim]\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "TqbZmOwudA5z"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "embedding_dim = 100\n",
        "hidden_dim = 256\n",
        "output_dim = 2  # binary classification\n",
        "n_layers = 2\n",
        "dropout = 0.5\n",
        "\n",
        "model = LSTMClassifier(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout)\n",
        "# model = model.to(device)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "vKzhgRufdMYK"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    for batch in tqdm(iterator, desc=\"Training\"):\n",
        "        sequences, labels = batch\n",
        "        sequences, labels = sequences.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        predictions = model(sequences)\n",
        "\n",
        "        loss = criterion(predictions, labels)\n",
        "        acc = ((predictions.argmax(1) == labels).float().sum() / len(labels)).item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "IJvBB9NYdsLP"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(iterator, desc=\"Evaluating\"):\n",
        "            sequences, labels = batch\n",
        "            sequences, labels = sequences.to(device), labels.to(device)\n",
        "\n",
        "            predictions = model(sequences)\n",
        "\n",
        "            loss = criterion(predictions, labels)\n",
        "            acc = ((predictions.argmax(1) == labels).float().sum() / len(labels)).item()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc\n",
        "\n",
        "            all_preds.extend(predictions.argmax(1).cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), all_preds, all_labels"
      ],
      "metadata": {
        "id": "oKpoFXR6dtpT"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "n_epochs = 10\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "valid_losses = []\n",
        "valid_accs = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
        "    valid_loss, valid_acc, predictions, labels = evaluate(model, test_loader, criterion)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    valid_losses.append(valid_loss)\n",
        "    valid_accs.append(valid_acc)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\tValid Loss: {valid_loss:.3f} | Valid Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'lstm_prompt_classifier.pt')\n",
        "        print(f'\\tModel saved with validation loss: {valid_loss:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "BuUGOjdvd00a",
        "outputId": "527f7289-85ba-4aa0-a224-47a38f16fc5d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 0/10 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'device' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-3cff7b80e90b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-660dff446920>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(valid_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accs, label='Training Accuracy')\n",
        "plt.plot(valid_accs, label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gqkBHfCteFwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final evaluation\n",
        "model.load_state_dict(torch.load('lstm_prompt_classifier.pt'))\n",
        "test_loss, test_acc, predictions, labels = evaluate(model, test_loader, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
        "\n",
        "# Classification report\n",
        "idx_to_label = {v: k for k, v in label_to_idx.items()}\n",
        "pred_labels = [idx_to_label[pred] for pred in predictions]\n",
        "true_labels = [idx_to_label[label] for label in labels]\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(true_labels, pred_labels))"
      ],
      "metadata": {
        "id": "M0--QmSkeTEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(true_labels, pred_labels, labels=list(label_to_idx.keys()))\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(label_to_idx))\n",
        "plt.xticks(tick_marks, label_to_idx.keys(), rotation=45)\n",
        "plt.yticks(tick_marks, label_to_idx.keys())\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ksYRr74geTxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict on new text\n",
        "def predict_text(text, model, word_to_idx, idx_to_label):\n",
        "    model.eval()\n",
        "\n",
        "    # Preprocess text\n",
        "    text = clean_text(text)\n",
        "    sequence = text_to_sequence(text, word_to_idx)\n",
        "    tensor = torch.tensor(sequence).unsqueeze(0).to(device)  # Add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prediction = model(tensor)\n",
        "        prob = torch.softmax(prediction, dim=1)\n",
        "        label_idx = prediction.argmax(1).item()\n",
        "        confidence = prob[0][label_idx].item()\n",
        "\n",
        "    return {\n",
        "        'label': idx_to_label[label_idx],\n",
        "        'confidence': confidence,\n",
        "        'probabilities': {\n",
        "            'Safe': prob[0][0].item(),\n",
        "            'Harmful': prob[0][1].item()\n",
        "        }\n",
        "    }"
      ],
      "metadata": {
        "id": "1ae6b7yDeWLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "test_prompt = \"Write a poem about flowers and sunshine\"\n",
        "idx_to_label = {v: k for k, v in label_to_idx.items()}\n",
        "result = predict_text(test_prompt, model, word_to_idx, idx_to_label)\n",
        "print(f\"\\nPrediction for: '{test_prompt}'\")\n",
        "print(f\"Label: {result['label']}\")\n",
        "print(f\"Confidence: {result['confidence']:.4f}\")\n",
        "print(f\"Probabilities: Safe: {result['probabilities']['Safe']:.4f}, Harmful: {result['probabilities']['Harmful']:.4f}\")"
      ],
      "metadata": {
        "id": "mXTh1fvMeZWI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}